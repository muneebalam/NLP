{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = '/Users/muneebalam/Desktop/Imperial/ML/project/speeches/'\n",
    "def parse_counterterror():\n",
    "    fname = 'counterterrorism cfr.txt'\n",
    "    r = open(folder + fname, 'r')\n",
    "    data = r.read()\n",
    "    r.close()\n",
    "    \n",
    "    paras = []\n",
    "    \n",
    "    data = data.split('ZAKARIA')\n",
    "    for i in range(len(data)):\n",
    "        if 'CLINTON' in data[i]:\n",
    "            data[i] = data[i][data[i].index('CLINTON')+8:]\n",
    "        else:\n",
    "            data[i] = ''\n",
    "        data[i] = [x.strip() for x in data[i].split('\\n')]\n",
    "        for j in range(len(data[i])):\n",
    "            if len(data[i][j]) > 0:\n",
    "                paras.append(data[i][j])\n",
    "    return paras\n",
    "def parse_me_atl():\n",
    "    fname = 'middle east atlantic.txt'\n",
    "    r = open(folder + fname, 'r')\n",
    "    data = r.read()\n",
    "    r.close()\n",
    "    \n",
    "    data = data.split('JG:')\n",
    "    paras = []\n",
    "    for i in range(len(data)):\n",
    "        if i == 0:\n",
    "            if 'HILLARY RODHAM CLINTON:' in data[i]:\n",
    "                data[i] = data[i][data[i].index('HILLARY RODHAM CLINTON:')+23:]\n",
    "        else:\n",
    "            if 'HRC:' in data[i]:\n",
    "                data[i] = data[i][data[i].index('HRC:')+4:]\n",
    "            else:\n",
    "                data[i] = ''\n",
    "        data[i] = [x.strip() for x in data[i].split('\\n')]\n",
    "        for j in range(len(data[i])):\n",
    "            if len(data[i][j]) > 0:\n",
    "                paras.append(data[i][j])\n",
    "    \n",
    "    return paras\n",
    "def parse_strint_cfr():\n",
    "    fname = 'strategic interests cfr.txt'\n",
    "    r = open(folder + fname, 'r')\n",
    "    data = r.read()\n",
    "    r.close()\n",
    "    \n",
    "    data = data.split('HAASS:')\n",
    "    paras = []\n",
    "    for i in range(len(data)):\n",
    "        if 'CLINTON:' in data[i]:\n",
    "            data[i] = data[i][data[i].index('CLINTON:')+8:]\n",
    "        else:\n",
    "            data[i] = ''\n",
    "        data[i] = [x.strip() for x in data[i].split('\\n')]\n",
    "        for j in range(len(data[i])):\n",
    "            if len(data[i][j]) > 0:\n",
    "                paras.append(data[i][j])\n",
    "                \n",
    "    return paras\n",
    "def parse_tradepbs():\n",
    "    fname = 'trade pbs.txt'\n",
    "    r = open(folder + fname, 'r')\n",
    "    data = r.read()\n",
    "    r.close()\n",
    "    \n",
    "    data = data.split('JUDY WOODRUFF:')\n",
    "    paras = []\n",
    "    for i in range(len(data)):\n",
    "        if 'HILLARY CLINTON:' in data[i]:\n",
    "            data[i] = data[i][data[i].index('HILLARY CLINTON:')+16:]\n",
    "        else:\n",
    "            data[i] = ''\n",
    "        data[i] = [x.strip() for x in data[i].split('\\n')]\n",
    "        for j in range(len(data[i])):\n",
    "            if len(data[i][j]) > 0:\n",
    "                paras.append(data[i][j])\n",
    "    return paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfrct = parse_counterterror()\n",
    "atlme = parse_me_atl()\n",
    "cfrsi = parse_strint_cfr()\n",
    "pbstr = parse_tradepbs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined = cfrct + atlme + cfrsi + pbstr\n",
    "sources = ['CFR Counterterrorism'] * len(cfrct) + ['The Atlantic']*len(atlme) + ['CFR Middle East']*len(cfrsi) + ['PBS']*len(pbstr)\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([tup for tup in zip(sources, combined)], columns=['Source', 'Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_nrc():\n",
    "    #returns {word: (positive/negative, {emotions})}\n",
    "    r = open('/Users/muneebalam/Desktop/Imperial/ML/project/NRC-Emotion-Lexicon/NRC-emotion-lexicon-wordlevel-alphabetized-v0.92.txt')\n",
    "    data = r.read().strip()\n",
    "    r.close()\n",
    "    \n",
    "    firstword = 'aback'\n",
    "    data = data[data.index(firstword):].split('\\n')\n",
    "    lex = {}\n",
    "    generalset = {'positive', 'negative'}\n",
    "    for line in data:\n",
    "        word, emot, posneg = line.split('\\t')\n",
    "        posneg = int(posneg)\n",
    "        if word not in lex:\n",
    "            lex[word] = [None, set()]\n",
    "        if posneg == 1:\n",
    "            if emot in generalset:\n",
    "                lex[word][0] = emot\n",
    "            else:\n",
    "                lex[word][1].add(emot)\n",
    "    return lex\n",
    "sent_dct = read_nrc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_word_lst = set(stopwords.words('english'))\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "opposites = {'anger': 'fear', 'anticipation': 'surprise', 'disgust': 'trust', 'fear': 'anger', \n",
    "             'joy': 'sadness', 'sadness': 'joy', 'surprise': 'anticipation', 'trust': 'disgust',\n",
    "            'positive': 'negative', 'negative': 'positive'}\n",
    "negation_words = {'not'}\n",
    "def split_by_sentences(text):\n",
    "    return text.replace('?', '.').replace('!', '.').replace(';', '.').split('. ')\n",
    "def split_by_words(text):\n",
    "    return [x.strip() for x in text.replace(',', '').replace('-', ' ')\n",
    "            .replace(':', '').replace('â€”', '').split(' ')]\n",
    "def findemot(text):\n",
    "    emots = {'anger': 0, 'anticipation': 0, 'disgust': 0, 'fear': 0,\n",
    "        'joy': 0, 'sadness': 0, 'surprise': 0, 'trust': 0}\n",
    "    posnegneu = {'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "    wordcount = 0\n",
    "    #https://en.wikipedia.org/wiki/Contrasting_and_categorization_of_emotions#Plutchik.27s_wheel_of_emotions\n",
    "    #emotions have opposites\n",
    "    try:\n",
    "        sentences = split_by_sentences(text)\n",
    "        if len(sentences) == 1:\n",
    "            negation = False\n",
    "            words = split_by_words(text)\n",
    "            for word in words:\n",
    "                wordcount += 1\n",
    "                if word in negation_words:\n",
    "                    negation = not negation\n",
    "                if word in stop_word_lst:\n",
    "                    pass\n",
    "                else:\n",
    "                    if word in sent_dct:\n",
    "                        if sent_dct[word][0] is None:\n",
    "                            posnegneu['neutral'] += 1\n",
    "                        else:\n",
    "                            if negation:\n",
    "                                posnegneu[opposites[sent_dct[word][0]]] += 1\n",
    "                            else:\n",
    "                                posnegneu[sent_dct[word][0]] += 1\n",
    "                        for em in sent_dct[word][1]:\n",
    "                            if negation:\n",
    "                                emots[opposites[em]] += 1\n",
    "                            else:\n",
    "                                emots[em] += 1\n",
    "                    else:\n",
    "                        word2 = SnowballStemmer(\"english\").stem(word)\n",
    "                        if word2 in sent_dct:\n",
    "                            if sent_dct[word2][0] is None:\n",
    "                                posnegneu['neutral'] += 1\n",
    "                            else:\n",
    "                                if negation:\n",
    "                                    posnegneu[opposites[sent_dct[word2][0]]] += 1\n",
    "                                else:\n",
    "                                    posnegneu[sent_dct[word2][0]] += 1\n",
    "                            for em in sent_dct[word2][1]:\n",
    "                                if negation:\n",
    "                                    emots[opposites[em]] += 1\n",
    "                                else:\n",
    "                                    emots[em] += 1\n",
    "        else:\n",
    "            sents = [findemot(sen) for sen in sentences]\n",
    "            for sen_pnn, sen_emot, wc in sents:\n",
    "                wordcount += wc\n",
    "                for sen in sen_pnn:\n",
    "                    posnegneu[sen] += sen_pnn[sen]\n",
    "                for sen in sen_emot:\n",
    "                    emots[sen] += sen_emot[sen]\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    return posnegneu, emots, wordcount\n",
    "def extract_anger(dcts):\n",
    "    return dcts[1]['anger']\n",
    "def extract_anticipation(dcts):\n",
    "    return dcts[1]['anticipation']\n",
    "def extract_disgust(dcts):\n",
    "    return dcts[1]['disgust']\n",
    "def extract_fear(dcts):\n",
    "    return dcts[1]['fear']\n",
    "def extract_joy(dcts):\n",
    "    return dcts[1]['joy']\n",
    "def extract_sadness(dcts):\n",
    "    return dcts[1]['sadness']\n",
    "def extract_surprise(dcts):\n",
    "    return dcts[1]['surprise']\n",
    "def extract_trust(dcts):\n",
    "    return dcts[1]['trust']\n",
    "def extract_positive(dcts):\n",
    "    return dcts[0]['positive']\n",
    "def extract_negative(dcts):\n",
    "    return dcts[0]['negative']\n",
    "def extract_neutral(dcts):\n",
    "    return dcts[0]['neutral']\n",
    "def extract_wordcount(dcts):\n",
    "    return dcts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emots = {'anger': extract_anger, 'anticipation': extract_anticipation, \n",
    "         'disgust': extract_disgust, 'fear': extract_fear,\n",
    "        'joy': extract_joy, 'sadness': extract_sadness, \n",
    "         'surprise': extract_surprise, 'trust': extract_trust}\n",
    "posnegneu = {'positive': extract_positive, 'negative': extract_negative, \n",
    "             'neutral': extract_neutral}\n",
    "df['sentinfo'] = df['Text'].apply(findemot) \n",
    "for e in emots:\n",
    "    df[e] = df['sentinfo'].apply(emots[e])\n",
    "for e in posnegneu:\n",
    "    df[e] = df['sentinfo'].apply(posnegneu[e])\n",
    "df['wordcount'] = df['sentinfo'].apply(extract_wordcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop('sentinfo', axis=1, inplace=True)\n",
    "df.to_csv(folder + 'speeches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
